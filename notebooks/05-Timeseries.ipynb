{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas started out in the financial world, so it naturally has strong support for timeseries data.\n",
    "We'll look at some pandas data types and methods for manipulating timeseries data.\n",
    "Afterwords, we'll use [statsmodels' state space framework](http://www.statsmodels.org/stable/statespace.html) to model timeseries data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datatypes\n",
    "\n",
    "- `pd.Timestamp` (nanosecond resolution `datetime.datetime`)\n",
    "- `pd.Timedelta` (nanosecond resolution `datetime.timedelta`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas provides highly-performant (mostly) drop-in replacements for `datetime.datetime` (`pd.Timestamp`) and `datetime.tiemedelta` (`pd.Timedelta`).\n",
    "These have been tailored for efficient storage in NumPy arrays.\n",
    "For the most part you'll be working with `DatetimeIndex`es or `TimedeltaIndex`es, or Series / DataFrames containing these.\n",
    "\n",
    "The biggest limitation is that pandas stores `Timestamp`s at nanosecond resolution. Since they're backed by NumPy's 64-bit integer, the minimum and maximum values are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Timestamp.min, pd.Timestamp.max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this is a problem, [there are workarounds](http://pandas.pydata.org/pandas-docs/stable/timeseries.html#representing-out-of-bounds-spans)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll go back to the BTS data set on flights.\n",
    "This time I've provided the number of flights per hour for two airports in Chicago: Midway (MDW) and O'Hare (ORD). The data go back to January 1st, 2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/flights-ts.csv.gz\", index_col=0, parse_dates=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling\n",
    "\n",
    "Resampling is similar to a groupby, but specialized for datetimes.\n",
    "Instead of specifying a column of values to group by, you  specify a `rule`: the desired output frequency.\n",
    "The original data is binned into each group created by your rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampler = df.resample(\"MS\")  # MS=Month Start\n",
    "resampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's an extensive list of frequency codes: http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases.\n",
    "\n",
    "If you examine the raw data in `df`, you'll notice that it's not at a fixed frequency.\n",
    "Hours where there weren't any flights just simply aren't present.\n",
    "This isn't a problem though; resample is perfect for going from \"ragged\" timeseries data to fixed-frequency data.\n",
    "\n",
    "Just like with `.groupby`, `.resample` returns a deferred object that hasn't really done any work yet.\n",
    "It has methods for aggregation, transformation, and general function application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampler.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampler.sum().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" data-title=\"Resample\">\n",
    "  <h1><i class=\"fa fa-tasks\" aria-hidden=\"true\"></i> Exercise: Resample</h1>\n",
    "</div>\n",
    "<p>Plot the standard deviation for the number of flights from `MDW` and `ORD` at a weekly frequency</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load solutions/timeseries_resample.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" data-title=\"Resample-Agg\">\n",
    "  <h1><i class=\"fa fa-tasks\" aria-hidden=\"true\"></i> Exercise: Resample-Agg</h1>\n",
    "</div>\n",
    "<p>Compute the the total number of flights (sum), mean, and median flights *per Quarter*.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load solutions/timeseries_resample_agg.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling, Expanding\n",
    "\n",
    "Applying functions to windows, moving through your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are very similar to groupby and resample. Let's get the daily number of flights with a `resample` quick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = df.resample('D').sum()\n",
    "daily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you wanted a 30-day moving (or rolling) average.\n",
    "This is possible with the `.rolling` method. Like `groupby` and `resample`, this object is just going to store the information to know what subset of data to operate on next; it doesn't actually do any work yet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily.rolling(30, center=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first argument is the window size.\n",
    "Since `daily` is at daily frequency, 30 means a 30-day window.\n",
    "`center=True` says to label each window with the middle-most point.\n",
    "To actually do work, you call a method like `.mean`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "daily.rolling(30).mean().rename(columns=lambda x: x + \" (30D MA)\").plot(ax=ax, alpha=.25,\n",
    "                                                                        color=['C0', 'C1'])\n",
    "daily.plot(ax=ax, alpha=.25, color=['C0', 'C1'], legend=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's common to combine resampling and rolling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.resample(\"D\").sum().rolling(30).corr(pairwise=True).xs(\"MDW\", level=1)['ORD'].plot(\n",
    "    title=\"O'Hare : Midway cross-correlation (30D MA)\", figsize=(12, 4)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timezones\n",
    "\n",
    "pandas can store an array of datetimes with a common timezone.\n",
    "Right now the index for `df` is timezone naïve, but we can convert to a timezone with `tz_convert`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.tzinfo  # None, timezone naïve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.tz_localize(\"US/Central\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timezones, as usual, are annoying to deal with.\n",
    "We've hit a daylight savings time issue.\n",
    "As the error says, 2000-04-02T02:00:00 isn't actaully a valid time in US/Central.\n",
    "I checked the BTS website, and these timestamps are supposed to be local time, so presumably some data was recorded incorrectly.\n",
    "pandas is strict by default, so it we need to tell it to ignore those errors: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df.index.tz_localize(\"US/Central\", ambiguous=\"NaT\", errors='coerce')\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(idx).sum()  # 25 bad values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the dtype: `datetime64[ns, US/Central]`.\n",
    "That means nanosecond resolution in the US/Central time zone.\n",
    "Once you have a datetime with timezone, you can convert timezones with `tz_convert`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx.tz_convert(\"UTC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offsets\n",
    "\n",
    "I wish the standard library `datetime` module had something like this.\n",
    "Let's generate some fake data with `pd.date_range`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range(\"2016-01-01\", end=\"2016-12-31\", freq='D')\n",
    "dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a whole bunch of offsets available in the `pd.tseries.offsets` namespace. For example, to move 3 business days into the future:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates + pd.tseries.offsets.BDay(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or to move to the next month end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates + pd.tseries.offsets.MonthEnd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timedelta Math\n",
    "\n",
    "Being able to add columns of dates and timedeltas turns out to be quite convenient.\n",
    "Let's go all the way back to our first example with flight delays from New York airports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = pd.read_csv(\"data/ny-flights.csv.gz\", parse_dates=['dep', 'arr'])\n",
    "flights.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" data-title=\"Convert Timedelta\">\n",
    "  <h1><i class=\"fa fa-tasks\" aria-hidden=\"true\"></i> Exercise: Convert Timedelta</h1>\n",
    "</div>\n",
    "<p>Convert `flights.dep_delay` and `flights.arr_delay` to timedelta dtype.</p>\n",
    "\n",
    "- Hint: recall our type conversion methods: `pd.to_*`\n",
    "- Make new columns in `flights` called `dep_delay_td` and `arr_delay_td`\n",
    "- Check the `unit` argument for the conversion method. The delay columns are in *minutes*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load solutions/timeseries_timedelta.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" data-title=\"Timedelta Math\">\n",
    "  <h1><i class=\"fa fa-tasks\" aria-hidden=\"true\"></i> Exercise: Timedelta Math</h1>\n",
    "</div>\n",
    "<p>Compute the actual time the flight left, but adding the departure time `dep` and the delay `dep_delay`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load solutions/timeseries_departure.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Timeseries\n",
    "\n",
    "Timeseries are an interesting problem to model.\n",
    "If we're lucky, we have a long history of past data that we can (maybe) use to predict the future.\n",
    "We can exploit regularity in the timeseries (seasonal patterns, periods of high values are typically followed by another high value, etc.) to better predict the future.\n",
    "\n",
    "Statsmodels has a nice framework for fitting timeseries models and evaluating their output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.tsa.api as smt\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's model Monthly flights from `ORD`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = daily.ORD.resample(\"MS\").sum()\n",
    "y.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That final value is odd because it's not a complete month. Let's drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = daily.ORD.resample(\"MS\").sum().iloc[:-1]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's common to estimate the parameters on *differenced* values.\n",
    "That is, make a new series $y'$ where $y_t' = y_t - y_{t-1}$. Pandas makes this simple with the `.diff` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prime = y.diff()\n",
    "y_prime.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll drop that first NaN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prime = y.diff().dropna()\n",
    "y_prime.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think back to regular linear regression: Predict some variable $y$ with some matrix $X$:\n",
    "\n",
    "$y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 ... + \\beta_p X_p + \\varepsilon$\n",
    "\n",
    "When modelling timeseries, past values of $y$ make for good components of $X$.\n",
    "We can do this with the pandas `.shift` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prime.shift()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the value for `2001-01-01` (-867) is now labeled `2000-02-01`. We can collect many of these with a list comprehension and a `concat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagged = pd.concat([y_prime.shift(i) for i in range(9)], axis=1,\n",
    "                   keys=['y', 'L1', 'L2', 'L3', 'L4', 'L5', 'L6', 'L7', 'L8'])\n",
    "lagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_lagged = smf.ols('y ~ L1 + L2 + L3 + L4 + L5 + L6 + L7 + L8', lagged)\n",
    "res_lagged = mod_lagged.fit()\n",
    "\n",
    "res_lagged.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = res_lagged.fittedvalues.plot(label=\"predicted\", figsize=(12, 4), legend=True)\n",
    "y_prime.plot(label=\"actual\", legend=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, you won't be doing the `shift`ing and `diff`ing yourself.\n",
    "It's more convenient to let statsmodels do that for us.\n",
    "Then we don't have to worry about un-differencing the fitted / predicted results to interpret them correctly.\n",
    "Also, the solvers we'll see next are a bit more sophisticated than a linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoRegressive Model\n",
    "\n",
    "Predict $y_{t+1}$, given $y_0, y_1, \\ldots y_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit an autoregressive (AR) model. Autoregressive part just means using past values of $y$ to predict the future (like we did above).\n",
    "We'll use statsmodel's `SARIMAX` model. The AR part of SARIMAX is for autoregressive.\n",
    "It also handles seasonality (**S**), differencing (**I** for integrated), moving average (**MA**), and exogenous regressors (**X**).\n",
    "\n",
    "We'll stick to a simple AR(8) model (use the last 8 periods) with a single period of differencing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = smt.SARIMAX(y, order=(8, 1, 0))  # AR(8), first difference, no MA\n",
    "res = mod.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual with statsmodels, we get a nice summary with the fitted coefficeints and some test statistics (which we'll ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results instance has all the usual attributes and methods, like `fittedvalues`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = res.fittedvalues.iloc[1:].plot(label=\"Fitted\", legend=True, figsize=(12, 4))\n",
    "y.plot(ax=ax, label=\"Actual\", legend=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting\n",
    "\n",
    "The real value of timeseries analysis is to predict the future.\n",
    "We can use the `.get_prediction` method to get the predicted values, along with a confidence interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll look at one-period-ahead forecasts.\n",
    "Basically, this simulates looking at our data the last day of the month, and making the forecast for the next month.\n",
    "Keep in mind though that we fit our parameters on the entire dataset. The isn't an out-of-sample prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = res.get_prediction(start='2001-03-01')\n",
    "pred_ci = pred.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = y.plot(label='observed')\n",
    "pred.predicted_mean.plot(ax=ax, label='Forecast', alpha=.7)\n",
    "ax.fill_between(pred_ci.index,\n",
    "                pred_ci.iloc[:, 0],\n",
    "                pred_ci.iloc[:, 1], color='k', alpha=.2)\n",
    "plt.legend()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can make dynamic forecasts as of some month (January 2013 in the example below). That means the forecast from that point forward only use information available as of January 2013 (though again, we fit the model on the entire dataset). The predictions are generated in a similar way: a bunch of one-step forecasts. Only instead of plugging in the actual values beyond January 2013, we plug in the forecast values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dy = res.get_prediction(start='2002-03-01', dynamic='2013-01-01')\n",
    "pred_dy_ci = pred_dy.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = y.plot(label='observed')\n",
    "pred_dy.predicted_mean.plot(ax=ax, label='Forecast')\n",
    "ax.fill_between(pred_dy_ci.index,\n",
    "                pred_dy_ci.iloc[:, 0],\n",
    "                pred_dy_ci.iloc[:, 1], color='k', alpha=.25)\n",
    "ylim = ax.get_ylim()\n",
    "ax.fill_betweenx(ylim, pd.Timestamp('2013-01-01'), y.index[-1],\n",
    "                 alpha=.1, zorder=-1)\n",
    "ax.set_ylim(ylim)\n",
    "ax.annotate('Dynamic $\\\\longrightarrow$',\n",
    "            (pd.Timestamp('2013-02-01'), 16000))\n",
    "\n",
    "plt.legend()\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are *a lot* of issues we didn't cover here.\n",
    "Seasonality, non-stationarity, autocorrellation, unit roots, and more.\n",
    "Timeseries modeling is fraught with traps that will throw off your predictions.\n",
    "Still, this should give you a taste of what's possbile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Resources\n",
    "\n",
    "- [statsmodels state space documentation](http://www.statsmodels.org/dev/statespace.html)\n",
    "- [statsmodels state space examples](http://www.statsmodels.org/dev/examples/index.html#statespace)\n",
    "- [pyflux](http://www.pyflux.com), another time series modeling library\n",
    "- Sean Abu's [post on ARIMA](http://www.seanabu.com/2016/03/22/time-series-seasonal-ARIMA-model-in-python/)\n",
    "- Jeffrey Yau's [talks at PyData](https://www.youtube.com/watch?v=tJ-O3hk1vRw)\n",
    "- My [blog post](http://tomaugspurger.github.io/modern-7-timeseries.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
